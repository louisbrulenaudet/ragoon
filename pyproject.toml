[project]
name = "ragoon"
version = "0.0.4"
description = "Improve large language models (LLM) retrieval using dynamic web-search based on blazingly fast query generation from Groq chips."
readme = "README.md"
keywords = ["language-models", "retrieval", "web-scraping", "few-shot-learning", "nlp", "machine-learning", "retrieval-augmented-generation", "RAG", "groq", "generative-ai", "llama", "Mistral"]
classifiers = [
    "Programming Language :: Python",
    "Programming Language :: Python :: 3",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development",
    "Topic :: Software Development :: Libraries",
    "Topic :: Software Development :: Libraries :: Python Modules"
]

[build-system]
requires = ["setuptools", "wheel"]
build-backend = "setuptools.build_meta"

[options]
packages = ["find:"]
install_requires = [
    "beautifulsoup4==4.12.3",
    "datasets==2.20.0",
    "faiss_cpu==1.8.0",
    "google_api_python_client==2.126.0",
    "groq==0.9.0",
    "httpx==0.27.0",
    "huggingface_hub==0.24.2",
    "numpy<2",
    "numpydoc==1.7.0",
    "openai==1.37.1",
    "plotly==5.23.0",
    "pydata-sphinx-theme==0.15.4",
    "pytest==8.3.2",
    "scikit_learn==1.5.1",
    "sentence_transformers==3.0.1",
    "sphinx==7.4.7",
    "torch==2.2.1",
    "tqdm==4.66.4",
    "umap==0.1.1",
    "umap_learn==0.5.6",
    "usearch==2.12.0"
]

[tool.pytest.ini_options]
testpaths = [
    "tests"
]

[project.optional-dependencies]
docs = [
    "sphinx>=6.0.0",
    "sphinx-book-theme>=1.0.1",  # Older versions fail to pin pydata-sphinx-theme
    "sphinxcontrib-katex",
    "sphinx-autodoc-typehints",
    "ipython>=8.8.0",  # 8.7.0 has ipython3 lexer error
    "myst-nb>=1.0.0",
    "matplotlib>=3.5.0",
    "sphinx-gallery>=0.14.0",
    "sphinx-collections>=0.0.1",
    "tensorflow>=2.4.0",
    "tensorflow-datasets>=4.2.0",
    "flax",
    "sphinx_contributors",
]

[tool.env]
PYTHONPATH = "src"

[metadata]
name = "ragoon"
version = "0.0.4"
license = "Apache License 2.0"
author = "Louis Brul√© Naudet"
author_email = "louisbrulenaudet@icloud.com"
description = "Improve large language models (LLM) retrieval using dynamic web-search based on blazingly fast query generation from Groq chips."
long_description = "file: README.md"
long_description_content_type = "text/markdown"
url = "https://github.com/louisbrulenaudet/ragoon"
homepage = "https://github.com/louisbrulenaudet/ragoon"
project_urls = {repository = "https://github.com/louisbrulenaudet/ragoon"}
keywords = "language-models retrieval web-scraping few-shot-learning nlp machine-learning ai llama generative-ai groqapi groq rag retrieval-augmented-generation"