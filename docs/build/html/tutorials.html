
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>üñºÔ∏è Tutorials &#8212; RAGoon 0.0.5 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css?v=fd3f3429" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=6424ca4d"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorials';</script>
    <link rel="icon" href="_static/logo.svg"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="ragoon" href="modules.html" />
    <link rel="prev" title="üöÄ Installation" href="installation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.svg" class="logo__image only-light" alt="RAGoon 0.0.5 documentation - Home"/>
    <script>document.write(`<img src="_static/logo.svg" class="logo__image only-dark" alt="RAGoon 0.0.5 documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="installation.html">üöÄ Installation</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">üñºÔ∏è Tutorials</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">üìñ Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="modules.html">ragoon</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="api/ragoon.chunks.html">ragoon.chunks</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/ragoon.datasets.html">ragoon.datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/ragoon.embeddings.html">ragoon.embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/ragoon.similarity_search.html">ragoon.similarity_search</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/ragoon.web_rag.html">ragoon.web_rag</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/louisbrulenaudet/ragoon" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/tutorials.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>üñºÔ∏è Tutorials</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embeddings-production">Embeddings production</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#similarity-search">Similarity search</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embeddings-visualization">Embeddings visualization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamic-web-search">Dynamic web search</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="tutorials">
<h1>üñºÔ∏è Tutorials<a class="headerlink" href="#tutorials" title="Link to this heading">#</a></h1>
<p>This section provides an overview of different code blocks that can be executed with RAGoon to enhance your NLP and language model projects.</p>
<section id="embeddings-production">
<h2>Embeddings production<a class="headerlink" href="#embeddings-production" title="Link to this heading">#</a></h2>
<p>This class handles loading a dataset from Hugging Face, processing it to add embeddings using specified models, and provides methods to save and upload the processed dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ragoon</span> <span class="kn">import</span> <span class="n">EmbeddingsDataLoader</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>

<span class="c1"># Initialize the dataset loader with multiple models</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">EmbeddingsDataLoader</span><span class="p">(</span>
    <span class="n">token</span><span class="o">=</span><span class="s2">&quot;hf_token&quot;</span><span class="p">,</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;louisbrulenaudet/dac6-instruct&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">),</span>  <span class="c1"># If dataset is already loaded.</span>
    <span class="c1"># dataset_name=&quot;louisbrulenaudet/dac6-instruct&quot;,  # If you want to load the dataset from the class.</span>
    <span class="n">model_configs</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">,</span> <span class="s2">&quot;query_prefix&quot;</span><span class="p">:</span> <span class="s2">&quot;Query:&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;distilbert-base-uncased&quot;</span><span class="p">,</span> <span class="s2">&quot;query_prefix&quot;</span><span class="p">:</span> <span class="s2">&quot;Query:&quot;</span><span class="p">}</span>
        <span class="c1"># Add more model configurations as needed</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Uncomment this line if passing dataset_name instead of dataset.</span>
<span class="c1"># loader.load_dataset()</span>

<span class="c1"># Process the splits with all models loaded</span>
<span class="n">loader</span><span class="o">.</span><span class="n">process</span><span class="p">(</span>
    <span class="n">column</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">,</span>
    <span class="n">preload_models</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># To access the processed dataset</span>
<span class="n">processed_dataset</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">get_dataset</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">processed_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>You can also embed a single text using multiple models:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ragoon</span> <span class="kn">import</span> <span class="n">EmbeddingsDataLoader</span>

<span class="c1"># Initialize the dataset loader with multiple models</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">EmbeddingsDataLoader</span><span class="p">(</span>
    <span class="n">token</span><span class="o">=</span><span class="s2">&quot;hf_token&quot;</span><span class="p">,</span>
    <span class="n">model_configs</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;distilbert-base-uncased&quot;</span><span class="p">}</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Load models</span>
<span class="n">loader</span><span class="o">.</span><span class="n">load_models</span><span class="p">()</span>

<span class="c1"># Embed a single text with all loaded models</span>
<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;This is a single text for embedding.&quot;</span>
<span class="n">embedding_result</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">batch_encode</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="c1"># Output the embeddings</span>
<span class="nb">print</span><span class="p">(</span><span class="n">embedding_result</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="similarity-search">
<h2>Similarity search<a class="headerlink" href="#similarity-search" title="Link to this heading">#</a></h2>
<p>The SimilaritySearch class is instantiated with specific parameters to configure the embedding model and search infrastructure. The chosen model, louisbrulenaudet/tsdae-lemone-mbert-base, is likely a multilingual BERT model fine-tuned with TSDAE (Transfomer-based Denoising Auto-Encoder) on a custom dataset. This model choice suggests a focus on multilingual capabilities and improved semantic representations.</p>
<p>The cuda device specification leverages GPU acceleration, crucial for efficient processing of large datasets. The embedding dimension of 768 is typical for BERT-based models, representing a balance between expressiveness and computational efficiency. The ip (inner product) metric is selected for similarity comparisons, which is computationally faster than cosine similarity when vectors are normalized. The i8 dtype indicates 8-bit integer quantization, a technique that significantly reduces memory usage and speeds up similarity search at the cost of a small accuracy rade-off.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ragoon</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">dataset_loader</span><span class="p">,</span>
    <span class="n">SimilaritySearch</span><span class="p">,</span>
    <span class="n">EmbeddingsVisualizer</span>
<span class="p">)</span>
<span class="n">instance</span> <span class="o">=</span> <span class="n">SimilaritySearch</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;louisbrulenaudet/tsdae-lemone-mbert-base&quot;</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
    <span class="n">ndim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
    <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;ip&quot;</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;i8&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The encode method transforms raw text into dense vector representations. This process involves tokenization, where text is split into subword units, followed by passing these tokens through the neural network layers of the SentenceTransformer model. The resulting embeddings capture semantic information in a high-dimensional space, where similar concepts are positioned closer together. The method likely uses batching to efficiently process large datasets and may employ techniques like length sorting to optimize padding and reduce computational waste.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset_loader</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;louisbrulenaudet/dac6-instruct&quot;</span><span class="p">,</span>
    <span class="n">streaming</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span>
<span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">save_to_disk</span><span class="p">(</span><span class="s2">&quot;dataset.hf&quot;</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">instance</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">corpus</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>Binary quantization is an extreme form of dimensionality reduction, where each dimension of the embedding is represented by a single bit. This process involves setting a threshold (often the median value for each dimension across the dataset) and encoding values above this threshold as 1 and below as 0. While this dramatically reduces memory usage (compressing each embedding to just 96 bytes for a 768-dimensional vector), it also results in a more significant loss of information compared to other quantization methods. However, it enables extremely fast similarity computations using hardware-accelerated bitwise operations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ubinary_embeddings</span> <span class="o">=</span> <span class="n">instance</span><span class="o">.</span><span class="n">quantize_embeddings</span><span class="p">(</span>
    <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">,</span>
    <span class="n">quantization_type</span><span class="o">=</span><span class="s2">&quot;ubinary&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Int8 quantization maps the continuous embedding values to a discrete set of 256 values represented by 8-bit integers. This process typically involves scaling the original values to fit within the int8 range (-128 to 127) and may use techniques like asymmetric quantization to preserve more information. While less extreme than binary quantization, int8 still offers substantial memory savings (reducing each dimension to 1 byte) while preserving more of the original information. This quantization enables efficient SIMD (Single Instruction, Multiple Data) operations on modern CPUs, significantly accelerating similarity computations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">int8_embeddings</span> <span class="o">=</span> <span class="n">instance</span><span class="o">.</span><span class="n">quantize_embeddings</span><span class="p">(</span>
    <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">,</span>
    <span class="n">quantization_type</span><span class="o">=</span><span class="s2">&quot;int8&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<p>USEARCH is designed for high-performance approximate nearest neighbor search. The index creation process likely involves building a hierarchical structure, possibly a navigable small world (NSW) graph, which allows for efficient traversal during search operations. The use of int8 quantized embeddings enables USEARCH to leverage SIMD instructions for rapid distance calculations. The resulting index balances search speed and accuracy, allowing for fast retrieval with a controlled trade-off in precision.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">instance</span><span class="o">.</span><span class="n">create_usearch_index</span><span class="p">(</span>
    <span class="n">int8_embeddings</span><span class="o">=</span><span class="n">int8_embeddings</span><span class="p">,</span>
    <span class="n">index_path</span><span class="o">=</span><span class="s2">&quot;./usearch_int8.index&quot;</span><span class="p">,</span>
    <span class="n">save</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
<p>FAISS (Facebook AI Similarity Search) is a library that provides efficient similarity search and clustering of dense vectors. For binary vectors, FAISS typically uses specialized index structures like the BinaryFlat index. This index performs exhaustive search using Hamming distance, which can be computed extremely efficiently on modern hardware using XOR and bit count operations. The binary nature of the index allows for compact storage and very fast search operations, albeit with reduced granularity in similarity scores compared to float-based indices.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">instance</span><span class="o">.</span><span class="n">create_faiss_index</span><span class="p">(</span>
    <span class="n">ubinary_embeddings</span><span class="o">=</span><span class="n">ubinary_embeddings</span><span class="p">,</span>
    <span class="n">index_path</span><span class="o">=</span><span class="s2">&quot;./faiss_ubinary.index&quot;</span><span class="p">,</span>
    <span class="n">save</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The search process combines the strengths of both USEARCH and FAISS indices. It likely first uses the binary FAISS index for a rapid initial filtering step, leveraging the efficiency of Hamming distance calculations. The top candidates from this step (increased by the rescore_multiplier for better recall) are then refined using the more precise int8 USEARCH index. This two-stage approach balances speed and accuracy, allowing for quick pruning of unlikely candidates followed by more accurate rescoring.</p>
<p>The query is first encoded using the same model and quantization processes as the corpus. The rescore_multiplier of 4 means the initial retrieval fetches 40 candidates (4 * top_k), which are then reranked to produce the final top 10 results. This oversampling helps mitigate the potential loss of relevant results due to quantization approximations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">polars</span> <span class="k">as</span> <span class="nn">pl</span>

<span class="n">top_k_scores</span><span class="p">,</span> <span class="n">top_k_indices</span> <span class="o">=</span> <span class="n">instance</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
    <span class="n">query</span><span class="o">=</span><span class="s2">&quot;D√©finir le r√¥le d&#39;un interm√©diaire concepteur conform√©ment √† l&#39;article 1649 AE du Code g√©n√©ral des Imp√¥ts.&quot;</span><span class="p">,</span>
    <span class="n">top_k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">rescore_multiplier</span><span class="o">=</span><span class="mi">4</span>
<span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">dataframe</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">from_arrow</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">table</span><span class="p">)</span><span class="o">.</span><span class="n">with_row_index</span><span class="p">()</span>

<span class="k">except</span><span class="p">:</span>
    <span class="n">dataframe</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">from_arrow</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">table</span><span class="p">)</span><span class="o">.</span><span class="n">with_row_count</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;index&quot;</span>
    <span class="p">)</span>

<span class="n">scores_df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;index&quot;</span><span class="p">:</span> <span class="n">top_k_indices</span><span class="p">,</span>
            <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">top_k_scores</span>
        <span class="p">}</span>
<span class="p">)</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
    <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;index&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">UInt32</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">search_results</span> <span class="o">=</span> <span class="n">dataframe</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
    <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;index&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">is_in</span><span class="p">(</span><span class="n">top_k_indices</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">scores_df</span><span class="p">,</span>
    <span class="n">how</span><span class="o">=</span><span class="s2">&quot;inner&quot;</span><span class="p">,</span>
    <span class="n">on</span><span class="o">=</span><span class="s2">&quot;index&quot;</span>
<span class="p">)</span>

<span class="n">search_results</span>
</pre></div>
</div>
</section>
<section id="embeddings-visualization">
<h2>Embeddings visualization<a class="headerlink" href="#embeddings-visualization" title="Link to this heading">#</a></h2>
<p>This class provides functionality to load embeddings from a FAISS index, reduce their dimensionality using PCA and/or t-SNE, and visualize them in an interactive 3D plot.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ragoon</span> <span class="kn">import</span> <span class="n">EmbeddingsVisualizer</span>

<span class="n">visualizer</span> <span class="o">=</span> <span class="n">EmbeddingsVisualizer</span><span class="p">(</span>
    <span class="n">index_path</span><span class="o">=</span><span class="s2">&quot;path/to/index&quot;</span><span class="p">,</span>
    <span class="n">dataset_path</span><span class="o">=</span><span class="s2">&quot;path/to/dataset&quot;</span>
<span class="p">)</span>

<span class="n">visualizer</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;pca&quot;</span><span class="p">,</span>
    <span class="n">save_html</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">html_file_name</span><span class="o">=</span><span class="s2">&quot;embedding_visualization.html&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="dynamic-web-search">
<h2>Dynamic web search<a class="headerlink" href="#dynamic-web-search" title="Link to this heading">#</a></h2>
<p>RAGoon is a Python library that aims to improve the performance of language models by providing contextually relevant information through retrieval-based querying, web scraping, and data augmentation techniques. It integrates various APIs, enabling users to retrieve information from the web, enrich it with domain-specific knowledge, and feed it to language models for more informed responses.</p>
<p>RAGoon‚Äôs core functionality revolves around the concept of few-shot learning, where language models are provided with a small set of high-quality examples to enhance their understanding and generate more accurate outputs. By curating and retrieving relevant data from the web, RAGoon equips language models with the necessary context and knowledge to tackle complex queries and generate insightful responses.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">groq</span> <span class="kn">import</span> <span class="n">Groq</span>
<span class="c1"># from openai import OpenAI</span>
<span class="kn">from</span> <span class="nn">ragoon</span> <span class="kn">import</span> <span class="n">WebRAG</span>

<span class="c1"># Initialize RAGoon instance</span>
<span class="n">ragoon</span> <span class="o">=</span> <span class="n">WebRAG</span><span class="p">(</span>
    <span class="n">google_api_key</span><span class="o">=</span><span class="s2">&quot;your_google_api_key&quot;</span><span class="p">,</span>
    <span class="n">google_cx</span><span class="o">=</span><span class="s2">&quot;your_google_cx&quot;</span><span class="p">,</span>
    <span class="n">completion_client</span><span class="o">=</span><span class="n">Groq</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;your_groq_api_key&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Search and get results</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;I want to do a left join in Python Polars&quot;</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">ragoon</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
    <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span>
    <span class="n">completion_model</span><span class="o">=</span><span class="s2">&quot;Llama3-70b-8192&quot;</span><span class="p">,</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Print results</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="installation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">üöÄ Installation</p>
      </div>
    </a>
    <a class="right-next"
       href="modules.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">ragoon</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embeddings-production">Embeddings production</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#similarity-search">Similarity search</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embeddings-visualization">Embeddings visualization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamic-web-search">Dynamic web search</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Louis Brul√© Naudet
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2024, Louis Brul√© Naudet.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>